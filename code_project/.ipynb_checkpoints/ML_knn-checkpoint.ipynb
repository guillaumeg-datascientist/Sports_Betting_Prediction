{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0f298a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24ece0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, mutual_info_classif, f_classif, SelectFromModel, f_regression, mutual_info_regression, RFE, RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a431f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('atp_data_only_var.csv')\n",
    "df.drop(['Index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "25762f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 14518 #début année 2005\n",
    "end = 55459 #début covid 2020\n",
    "\n",
    "df = df.loc[start:end,:]\n",
    "\n",
    "size_dataset = len(df)\n",
    "proportion_train = 80\n",
    "\n",
    "size_train = size_dataset*proportion_train//100\n",
    "\n",
    "data = df.drop('target', axis = 1)\n",
    "target = df['target']\n",
    "\n",
    "X_train = data.loc[:start+size_train-1,:]\n",
    "y_train = target.loc[:start+size_train-1]\n",
    " \n",
    "X_test = data.loc[start+size_train:,:]\n",
    "y_test = target.loc[start+size_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319072c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81523ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "parametres = {'n_neighbors': range(2,40), 'metric' : ['manhattan', 'minkowski']}\n",
    "grid = model_selection.GridSearchCV(estimator=knn, param_grid=parametres)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\")\n",
    "print('Meilleurs paramètres :', grid.best_params_)\n",
    "print(\"\")\n",
    "print(\"Score obtenu :\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICI ON IMPLÉMENTE LES PARAMÈTRES OBTENUS\n",
    "knn = KNeighborsClassifier(n_neighbors=$$$, metric=$$$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici on regarde le nombre de features idéales\n",
    "\n",
    "clf = knn\n",
    "all_scores = []\n",
    "all_var = []\n",
    "\n",
    "for k in range(1, len(X_train.columns)+1) :\n",
    "    sel = SelectKBest(score_func = mutual_info_regression, k=k) \n",
    "    sel.fit(X_train, y_train)\n",
    "    mask = sel.get_support()\n",
    "\n",
    "    X_train_sel = X_train[X_train.columns[mask]]\n",
    "    X_test_sel = X_test[X_test.columns[mask]]\n",
    "\n",
    "    clf.fit(X_train_sel, y_train)\n",
    "    score = clf.score(X_test_sel, y_test)\n",
    "    all_scores.append(score)\n",
    "    all_var.append(X_train_sel.columns)\n",
    "    print((k, score))\n",
    "    \n",
    "best_score = (np.argmax(all_scores)+1, all_scores[np.argmax(all_scores)])\n",
    "\n",
    "print('Le meilleur score obtenue est :',best_score[1],'pour',best_score[0],'features')\n",
    "print('Les',best_score[1],'meilleures features retenues sont :', all_var[k-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
